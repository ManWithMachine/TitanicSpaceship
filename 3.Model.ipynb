{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "278ac3e6",
   "metadata": {},
   "source": [
    "# We processed the data, now we will use different models, train them and at the end make prediction that we will export and submit on Kaggle.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc0d9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import MultipleLocator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95929a95",
   "metadata": {},
   "source": [
    "### First we will export data and split to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1785ffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('training.csv')\n",
    "test = pd.read_csv('testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6accf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop('Transported', axis=1)\n",
    "y_train = data['Transported']\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8b5568",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ba17673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score: 0.7825925006208095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noobix/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "y_pred = logreg.predict(X_train)\n",
    "y_test_lg = logreg.predict(X_test)\n",
    "print('Train accuracy score:',accuracy_score(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8b5d7",
   "metadata": {},
   "source": [
    "### Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc48fd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score: 0.9997516761857462\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "predict = rfc.predict(X_train)\n",
    "y_test_rfc = rfc.predict(X_test)\n",
    "print('Train accuracy score:',accuracy_score(y_train,predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd00716",
   "metadata": {},
   "source": [
    "### K-Nearest Neigbhour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f71273c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score:  0.8208343680158927\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "predictions = knn.predict(X_train)\n",
    "y_test_knn = knn.predict(X_test)\n",
    "print('Train accuracy score: ',accuracy_score(y_train,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7460df60",
   "metadata": {},
   "source": [
    "### Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a47dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train = data.drop('Transported',axis=1)\n",
    "y_train = data['Transported']\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6b56499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 19:16:19.221354: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-16 19:16:19.221409: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-16 19:16:19.346449: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-16 19:16:20.942738: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-16 19:16:20.942953: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-16 19:16:20.942976: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25e83cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8054 entries, 0 to 8053\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Group         8054 non-null   int64  \n",
      " 1   HomePlanet    8054 non-null   float64\n",
      " 2   CryoSleep     8054 non-null   float64\n",
      " 3   Deck          8054 non-null   float64\n",
      " 4   Destination   8054 non-null   float64\n",
      " 5   Age           8054 non-null   float64\n",
      " 6   VIP           8054 non-null   float64\n",
      " 7   RoomService   8054 non-null   float64\n",
      " 8   FoodCourt     8054 non-null   float64\n",
      " 9   ShoppingMall  8054 non-null   float64\n",
      " 10  Spa           8054 non-null   float64\n",
      " 11  VRDeck        8054 non-null   float64\n",
      " 12  Transported   8054 non-null   bool   \n",
      "dtypes: bool(1), float64(11), int64(1)\n",
      "memory usage: 763.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a27eb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 19:16:58.435642: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-16 19:16:58.436405: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-16 19:16:58.436511: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (noobix): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "\n",
    "\n",
    "# input layer\n",
    "model.add(Dense(1024, activation='relu', input_shape=[12]))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# hidden layer\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b336fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "32/32 [==============================] - 4s 85ms/step - loss: 0.5530 - binary_accuracy: 0.7121\n",
      "Epoch 2/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.4910 - binary_accuracy: 0.7605\n",
      "Epoch 3/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.4661 - binary_accuracy: 0.7776\n",
      "Epoch 4/300\n",
      "32/32 [==============================] - 3s 105ms/step - loss: 0.4474 - binary_accuracy: 0.7830\n",
      "Epoch 5/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.4397 - binary_accuracy: 0.7914\n",
      "Epoch 6/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.4300 - binary_accuracy: 0.7965\n",
      "Epoch 7/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.4307 - binary_accuracy: 0.7903\n",
      "Epoch 8/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.4263 - binary_accuracy: 0.7945\n",
      "Epoch 9/300\n",
      "32/32 [==============================] - 3s 100ms/step - loss: 0.4222 - binary_accuracy: 0.7980\n",
      "Epoch 10/300\n",
      "32/32 [==============================] - 3s 90ms/step - loss: 0.4241 - binary_accuracy: 0.7953\n",
      "Epoch 11/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.4286 - binary_accuracy: 0.7940\n",
      "Epoch 12/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.4191 - binary_accuracy: 0.7985\n",
      "Epoch 13/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.4170 - binary_accuracy: 0.7991\n",
      "Epoch 14/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.4194 - binary_accuracy: 0.7987\n",
      "Epoch 15/300\n",
      "32/32 [==============================] - 3s 108ms/step - loss: 0.4132 - binary_accuracy: 0.7986\n",
      "Epoch 16/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.4095 - binary_accuracy: 0.8075\n",
      "Epoch 17/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.4104 - binary_accuracy: 0.8036\n",
      "Epoch 18/300\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.4072 - binary_accuracy: 0.8074\n",
      "Epoch 19/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.4083 - binary_accuracy: 0.8015\n",
      "Epoch 20/300\n",
      "32/32 [==============================] - 3s 96ms/step - loss: 0.4062 - binary_accuracy: 0.8030\n",
      "Epoch 21/300\n",
      "32/32 [==============================] - 3s 95ms/step - loss: 0.4039 - binary_accuracy: 0.8082\n",
      "Epoch 22/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.4050 - binary_accuracy: 0.8017\n",
      "Epoch 23/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.4013 - binary_accuracy: 0.8058\n",
      "Epoch 24/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.4009 - binary_accuracy: 0.8033\n",
      "Epoch 25/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3995 - binary_accuracy: 0.8056\n",
      "Epoch 26/300\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.3978 - binary_accuracy: 0.8049\n",
      "Epoch 27/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.3991 - binary_accuracy: 0.8072\n",
      "Epoch 28/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3980 - binary_accuracy: 0.8083\n",
      "Epoch 29/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.3972 - binary_accuracy: 0.8042\n",
      "Epoch 30/300\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.3958 - binary_accuracy: 0.8059\n",
      "Epoch 31/300\n",
      "32/32 [==============================] - 3s 97ms/step - loss: 0.3965 - binary_accuracy: 0.8064\n",
      "Epoch 32/300\n",
      "32/32 [==============================] - 3s 96ms/step - loss: 0.3938 - binary_accuracy: 0.8059\n",
      "Epoch 33/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3922 - binary_accuracy: 0.8104\n",
      "Epoch 34/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3943 - binary_accuracy: 0.8071\n",
      "Epoch 35/300\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.3953 - binary_accuracy: 0.8012\n",
      "Epoch 36/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3932 - binary_accuracy: 0.8041\n",
      "Epoch 37/300\n",
      "32/32 [==============================] - 3s 106ms/step - loss: 0.3882 - binary_accuracy: 0.8103\n",
      "Epoch 38/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3932 - binary_accuracy: 0.8078\n",
      "Epoch 39/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3911 - binary_accuracy: 0.8098\n",
      "Epoch 40/300\n",
      "32/32 [==============================] - 3s 95ms/step - loss: 0.3896 - binary_accuracy: 0.8093\n",
      "Epoch 41/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3885 - binary_accuracy: 0.8066\n",
      "Epoch 42/300\n",
      "32/32 [==============================] - 3s 104ms/step - loss: 0.3863 - binary_accuracy: 0.8090\n",
      "Epoch 43/300\n",
      "32/32 [==============================] - 3s 95ms/step - loss: 0.3890 - binary_accuracy: 0.8105\n",
      "Epoch 44/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3884 - binary_accuracy: 0.8097\n",
      "Epoch 45/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3907 - binary_accuracy: 0.8104\n",
      "Epoch 46/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3860 - binary_accuracy: 0.8090\n",
      "Epoch 47/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3820 - binary_accuracy: 0.8164\n",
      "Epoch 48/300\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.3834 - binary_accuracy: 0.8138\n",
      "Epoch 49/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3845 - binary_accuracy: 0.8094\n",
      "Epoch 50/300\n",
      "32/32 [==============================] - 3s 95ms/step - loss: 0.3844 - binary_accuracy: 0.8094\n",
      "Epoch 51/300\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.3819 - binary_accuracy: 0.8136\n",
      "Epoch 52/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3812 - binary_accuracy: 0.8115\n",
      "Epoch 53/300\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.3847 - binary_accuracy: 0.8120\n",
      "Epoch 54/300\n",
      "32/32 [==============================] - 3s 96ms/step - loss: 0.3831 - binary_accuracy: 0.8103\n",
      "Epoch 55/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3749 - binary_accuracy: 0.8175\n",
      "Epoch 56/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3786 - binary_accuracy: 0.8145\n",
      "Epoch 57/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3778 - binary_accuracy: 0.8133\n",
      "Epoch 58/300\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.3801 - binary_accuracy: 0.8103\n",
      "Epoch 59/300\n",
      "32/32 [==============================] - 3s 106ms/step - loss: 0.3771 - binary_accuracy: 0.8159\n",
      "Epoch 60/300\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.3760 - binary_accuracy: 0.8184\n",
      "Epoch 61/300\n",
      "32/32 [==============================] - 3s 108ms/step - loss: 0.3782 - binary_accuracy: 0.8149\n",
      "Epoch 62/300\n",
      "32/32 [==============================] - 3s 97ms/step - loss: 0.3761 - binary_accuracy: 0.8151\n",
      "Epoch 63/300\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.3759 - binary_accuracy: 0.8162\n",
      "Epoch 64/300\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.3762 - binary_accuracy: 0.8144\n",
      "Epoch 65/300\n",
      "32/32 [==============================] - 3s 92ms/step - loss: 0.3735 - binary_accuracy: 0.8157\n",
      "Epoch 66/300\n",
      "32/32 [==============================] - 3s 90ms/step - loss: 0.3745 - binary_accuracy: 0.8146\n",
      "Epoch 67/300\n",
      "32/32 [==============================] - 3s 90ms/step - loss: 0.3769 - binary_accuracy: 0.8126\n",
      "Epoch 68/300\n",
      "32/32 [==============================] - 4s 122ms/step - loss: 0.3746 - binary_accuracy: 0.8165\n",
      "Epoch 69/300\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.3703 - binary_accuracy: 0.8198\n",
      "Epoch 70/300\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.3749 - binary_accuracy: 0.8133\n",
      "Epoch 71/300\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.3715 - binary_accuracy: 0.8184\n",
      "Epoch 72/300\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.3704 - binary_accuracy: 0.8200\n",
      "Epoch 73/300\n",
      "32/32 [==============================] - 3s 106ms/step - loss: 0.3718 - binary_accuracy: 0.8171\n",
      "Epoch 74/300\n",
      "32/32 [==============================] - 3s 96ms/step - loss: 0.3677 - binary_accuracy: 0.8224\n",
      "Epoch 75/300\n",
      "32/32 [==============================] - 3s 90ms/step - loss: 0.3714 - binary_accuracy: 0.8169\n",
      "Epoch 76/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 3s 89ms/step - loss: 0.3709 - binary_accuracy: 0.8180\n",
      "Epoch 77/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3679 - binary_accuracy: 0.8215\n",
      "Epoch 78/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3661 - binary_accuracy: 0.8221\n",
      "Epoch 79/300\n",
      "32/32 [==============================] - 3s 104ms/step - loss: 0.3667 - binary_accuracy: 0.8212\n",
      "Epoch 80/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.3705 - binary_accuracy: 0.8190\n",
      "Epoch 81/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3662 - binary_accuracy: 0.8221\n",
      "Epoch 82/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.3678 - binary_accuracy: 0.8169\n",
      "Epoch 83/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3708 - binary_accuracy: 0.8192\n",
      "Epoch 84/300\n",
      "32/32 [==============================] - 3s 106ms/step - loss: 0.3654 - binary_accuracy: 0.8205\n",
      "Epoch 85/300\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 0.3645 - binary_accuracy: 0.8197\n",
      "Epoch 86/300\n",
      "32/32 [==============================] - 3s 98ms/step - loss: 0.3626 - binary_accuracy: 0.8239\n",
      "Epoch 87/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3625 - binary_accuracy: 0.8229\n",
      "Epoch 88/300\n",
      "32/32 [==============================] - 3s 93ms/step - loss: 0.3631 - binary_accuracy: 0.8223\n",
      "Epoch 89/300\n",
      "32/32 [==============================] - 3s 100ms/step - loss: 0.3605 - binary_accuracy: 0.8221\n",
      "Epoch 90/300\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.3620 - binary_accuracy: 0.8232\n",
      "Epoch 91/300\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.3634 - binary_accuracy: 0.8210\n",
      "Epoch 92/300\n",
      "32/32 [==============================] - 3s 100ms/step - loss: 0.3636 - binary_accuracy: 0.8226\n",
      "Epoch 93/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.3599 - binary_accuracy: 0.8246\n",
      "Epoch 94/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3617 - binary_accuracy: 0.8200\n",
      "Epoch 95/300\n",
      "32/32 [==============================] - 3s 98ms/step - loss: 0.3593 - binary_accuracy: 0.8256\n",
      "Epoch 96/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3618 - binary_accuracy: 0.8215\n",
      "Epoch 97/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.3639 - binary_accuracy: 0.8193\n",
      "Epoch 98/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3575 - binary_accuracy: 0.8236\n",
      "Epoch 99/300\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.3586 - binary_accuracy: 0.8257\n",
      "Epoch 100/300\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.3598 - binary_accuracy: 0.8259\n",
      "Epoch 101/300\n",
      "32/32 [==============================] - 3s 92ms/step - loss: 0.3570 - binary_accuracy: 0.8282\n",
      "Epoch 102/300\n",
      "32/32 [==============================] - 3s 94ms/step - loss: 0.3563 - binary_accuracy: 0.8238\n",
      "Epoch 103/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.3577 - binary_accuracy: 0.8253\n",
      "Epoch 104/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3564 - binary_accuracy: 0.8262\n",
      "Epoch 105/300\n",
      "32/32 [==============================] - 3s 90ms/step - loss: 0.3572 - binary_accuracy: 0.8237\n",
      "Epoch 106/300\n",
      "32/32 [==============================] - 3s 96ms/step - loss: 0.3547 - binary_accuracy: 0.8275\n",
      "Epoch 107/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3548 - binary_accuracy: 0.8272\n",
      "Epoch 108/300\n",
      "32/32 [==============================] - 3s 98ms/step - loss: 0.3555 - binary_accuracy: 0.8267\n",
      "Epoch 109/300\n",
      "32/32 [==============================] - 3s 90ms/step - loss: 0.3537 - binary_accuracy: 0.8237\n",
      "Epoch 110/300\n",
      "32/32 [==============================] - 3s 98ms/step - loss: 0.3531 - binary_accuracy: 0.8299\n",
      "Epoch 111/300\n",
      "32/32 [==============================] - 3s 108ms/step - loss: 0.3483 - binary_accuracy: 0.8285\n",
      "Epoch 112/300\n",
      "32/32 [==============================] - 3s 90ms/step - loss: 0.3544 - binary_accuracy: 0.8253\n",
      "Epoch 113/300\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.3511 - binary_accuracy: 0.8242\n",
      "Epoch 114/300\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.3531 - binary_accuracy: 0.8249\n",
      "Epoch 115/300\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.3526 - binary_accuracy: 0.8301\n",
      "Epoch 116/300\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 0.3498 - binary_accuracy: 0.8289\n",
      "Epoch 117/300\n",
      "32/32 [==============================] - 3s 92ms/step - loss: 0.3493 - binary_accuracy: 0.8310\n",
      "Epoch 118/300\n",
      "32/32 [==============================] - 3s 92ms/step - loss: 0.3518 - binary_accuracy: 0.8294\n",
      "Epoch 119/300\n",
      "32/32 [==============================] - 3s 94ms/step - loss: 0.3490 - binary_accuracy: 0.8300\n",
      "Epoch 120/300\n",
      "32/32 [==============================] - 3s 92ms/step - loss: 0.3481 - binary_accuracy: 0.8316\n",
      "Epoch 121/300\n",
      "32/32 [==============================] - 3s 105ms/step - loss: 0.3484 - binary_accuracy: 0.8316\n",
      "Epoch 122/300\n",
      "32/32 [==============================] - 3s 90ms/step - loss: 0.3454 - binary_accuracy: 0.8311\n",
      "Epoch 123/300\n",
      "32/32 [==============================] - 3s 99ms/step - loss: 0.3483 - binary_accuracy: 0.8296\n",
      "Epoch 124/300\n",
      "32/32 [==============================] - 3s 94ms/step - loss: 0.3453 - binary_accuracy: 0.8294\n",
      "Epoch 125/300\n",
      "32/32 [==============================] - 3s 95ms/step - loss: 0.3474 - binary_accuracy: 0.8290\n",
      "Epoch 126/300\n",
      "32/32 [==============================] - 4s 128ms/step - loss: 0.3451 - binary_accuracy: 0.8306\n",
      "Epoch 127/300\n",
      "32/32 [==============================] - 4s 130ms/step - loss: 0.3452 - binary_accuracy: 0.8323\n",
      "Epoch 128/300\n",
      "32/32 [==============================] - 3s 93ms/step - loss: 0.3445 - binary_accuracy: 0.8272\n",
      "Epoch 129/300\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.3415 - binary_accuracy: 0.8364\n",
      "Epoch 130/300\n",
      "32/32 [==============================] - 5s 168ms/step - loss: 0.3431 - binary_accuracy: 0.8344\n",
      "Epoch 131/300\n",
      "32/32 [==============================] - 3s 90ms/step - loss: 0.3439 - binary_accuracy: 0.8329\n",
      "Epoch 132/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.3429 - binary_accuracy: 0.8310\n",
      "Epoch 133/300\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.3438 - binary_accuracy: 0.8330\n",
      "Epoch 134/300\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.3417 - binary_accuracy: 0.8352\n",
      "Epoch 135/300\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 0.3396 - binary_accuracy: 0.8347\n",
      "Epoch 136/300\n",
      "32/32 [==============================] - 3s 98ms/step - loss: 0.3423 - binary_accuracy: 0.8331\n",
      "Epoch 137/300\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.3429 - binary_accuracy: 0.8326\n",
      "Epoch 138/300\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.3414 - binary_accuracy: 0.8311\n",
      "Epoch 139/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.3433 - binary_accuracy: 0.8330\n",
      "Epoch 140/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3416 - binary_accuracy: 0.8333\n",
      "Epoch 141/300\n",
      "32/32 [==============================] - 3s 95ms/step - loss: 0.3392 - binary_accuracy: 0.8337\n",
      "Epoch 142/300\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 0.3380 - binary_accuracy: 0.8349\n",
      "Epoch 143/300\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.3363 - binary_accuracy: 0.8369\n",
      "Epoch 144/300\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 0.3408 - binary_accuracy: 0.8335\n",
      "Epoch 145/300\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.3394 - binary_accuracy: 0.8323\n",
      "Epoch 146/300\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.3377 - binary_accuracy: 0.8350\n",
      "Epoch 147/300\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 0.3358 - binary_accuracy: 0.8380\n",
      "Epoch 148/300\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 0.3362 - binary_accuracy: 0.8354\n",
      "Epoch 149/300\n",
      "32/32 [==============================] - 4s 123ms/step - loss: 0.3347 - binary_accuracy: 0.8347\n",
      "Epoch 150/300\n",
      "32/32 [==============================] - 3s 101ms/step - loss: 0.3331 - binary_accuracy: 0.8369\n",
      "Epoch 151/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 3s 98ms/step - loss: 0.3327 - binary_accuracy: 0.8371\n",
      "Epoch 152/300\n",
      "32/32 [==============================] - 3s 83ms/step - loss: 0.3379 - binary_accuracy: 0.8341\n",
      "Epoch 153/300\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.3379 - binary_accuracy: 0.8377\n",
      "Epoch 154/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.3340 - binary_accuracy: 0.8388\n",
      "Epoch 155/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.3365 - binary_accuracy: 0.8364\n",
      "Epoch 156/300\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 0.3305 - binary_accuracy: 0.8367\n",
      "Epoch 157/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3328 - binary_accuracy: 0.8378\n",
      "Epoch 158/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3350 - binary_accuracy: 0.8335\n",
      "Epoch 159/300\n",
      "32/32 [==============================] - 3s 100ms/step - loss: 0.3360 - binary_accuracy: 0.8366\n",
      "Epoch 160/300\n",
      "32/32 [==============================] - 3s 100ms/step - loss: 0.3309 - binary_accuracy: 0.8362\n",
      "Epoch 161/300\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 0.3301 - binary_accuracy: 0.8383\n",
      "Epoch 162/300\n",
      "32/32 [==============================] - 3s 96ms/step - loss: 0.3347 - binary_accuracy: 0.8342\n",
      "Epoch 163/300\n",
      "32/32 [==============================] - 3s 99ms/step - loss: 0.3304 - binary_accuracy: 0.8402\n",
      "Epoch 164/300\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 0.3296 - binary_accuracy: 0.8411\n",
      "Epoch 165/300\n",
      "32/32 [==============================] - 3s 101ms/step - loss: 0.3281 - binary_accuracy: 0.8369\n",
      "Epoch 166/300\n",
      "32/32 [==============================] - 3s 108ms/step - loss: 0.3290 - binary_accuracy: 0.8414\n",
      "Epoch 167/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.3251 - binary_accuracy: 0.8439\n",
      "Epoch 168/300\n",
      "32/32 [==============================] - 3s 95ms/step - loss: 0.3284 - binary_accuracy: 0.8383\n",
      "Epoch 169/300\n",
      "32/32 [==============================] - 3s 108ms/step - loss: 0.3241 - binary_accuracy: 0.8417\n",
      "Epoch 170/300\n",
      "32/32 [==============================] - 3s 96ms/step - loss: 0.3288 - binary_accuracy: 0.8372\n",
      "Epoch 171/300\n",
      "32/32 [==============================] - 4s 123ms/step - loss: 0.3265 - binary_accuracy: 0.8408\n",
      "Epoch 172/300\n",
      "32/32 [==============================] - 3s 97ms/step - loss: 0.3227 - binary_accuracy: 0.8447\n",
      "Epoch 173/300\n",
      "32/32 [==============================] - 3s 96ms/step - loss: 0.3241 - binary_accuracy: 0.8419\n",
      "Epoch 174/300\n",
      "32/32 [==============================] - 3s 92ms/step - loss: 0.3310 - binary_accuracy: 0.8416\n",
      "Epoch 175/300\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.3215 - binary_accuracy: 0.8457\n",
      "Epoch 176/300\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 0.3223 - binary_accuracy: 0.8406\n",
      "Epoch 177/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3218 - binary_accuracy: 0.8437\n",
      "Epoch 178/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3211 - binary_accuracy: 0.8424\n",
      "Epoch 179/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3199 - binary_accuracy: 0.8450\n",
      "Epoch 180/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3219 - binary_accuracy: 0.8383\n",
      "Epoch 181/300\n",
      "32/32 [==============================] - 3s 97ms/step - loss: 0.3184 - binary_accuracy: 0.8453\n",
      "Epoch 182/300\n",
      "32/32 [==============================] - 3s 94ms/step - loss: 0.3201 - binary_accuracy: 0.8443\n",
      "Epoch 183/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3204 - binary_accuracy: 0.8448\n",
      "Epoch 184/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3223 - binary_accuracy: 0.8432\n",
      "Epoch 185/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3198 - binary_accuracy: 0.8433\n",
      "Epoch 186/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3201 - binary_accuracy: 0.8433\n",
      "Epoch 187/300\n",
      "32/32 [==============================] - 3s 105ms/step - loss: 0.3185 - binary_accuracy: 0.8426\n",
      "Epoch 188/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.3196 - binary_accuracy: 0.8467\n",
      "Epoch 189/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3193 - binary_accuracy: 0.8431\n",
      "Epoch 190/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3201 - binary_accuracy: 0.8412\n",
      "Epoch 191/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3193 - binary_accuracy: 0.8449\n",
      "Epoch 192/300\n",
      "32/32 [==============================] - 3s 92ms/step - loss: 0.3185 - binary_accuracy: 0.8484\n",
      "Epoch 193/300\n",
      "32/32 [==============================] - 3s 101ms/step - loss: 0.3161 - binary_accuracy: 0.8438\n",
      "Epoch 194/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.3182 - binary_accuracy: 0.8464\n",
      "Epoch 195/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.3129 - binary_accuracy: 0.8509\n",
      "Epoch 196/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.3169 - binary_accuracy: 0.8437\n",
      "Epoch 197/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3138 - binary_accuracy: 0.8488\n",
      "Epoch 198/300\n",
      "32/32 [==============================] - 3s 104ms/step - loss: 0.3159 - binary_accuracy: 0.8469\n",
      "Epoch 199/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3140 - binary_accuracy: 0.8453\n",
      "Epoch 200/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3142 - binary_accuracy: 0.8429\n",
      "Epoch 201/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3182 - binary_accuracy: 0.8493\n",
      "Epoch 202/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.3117 - binary_accuracy: 0.8470\n",
      "Epoch 203/300\n",
      "32/32 [==============================] - 3s 93ms/step - loss: 0.3131 - binary_accuracy: 0.8477\n",
      "Epoch 204/300\n",
      "32/32 [==============================] - 3s 97ms/step - loss: 0.3104 - binary_accuracy: 0.8505\n",
      "Epoch 205/300\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.3140 - binary_accuracy: 0.8458\n",
      "Epoch 206/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.3109 - binary_accuracy: 0.8495\n",
      "Epoch 207/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.3084 - binary_accuracy: 0.8478\n",
      "Epoch 208/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3103 - binary_accuracy: 0.8486\n",
      "Epoch 209/300\n",
      "32/32 [==============================] - 3s 104ms/step - loss: 0.3097 - binary_accuracy: 0.8526\n",
      "Epoch 210/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.3080 - binary_accuracy: 0.8499\n",
      "Epoch 211/300\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.3078 - binary_accuracy: 0.8501\n",
      "Epoch 212/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.3059 - binary_accuracy: 0.8503\n",
      "Epoch 213/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.3062 - binary_accuracy: 0.8495\n",
      "Epoch 214/300\n",
      "32/32 [==============================] - 3s 96ms/step - loss: 0.3073 - binary_accuracy: 0.8500\n",
      "Epoch 215/300\n",
      "32/32 [==============================] - 3s 101ms/step - loss: 0.3064 - binary_accuracy: 0.8472\n",
      "Epoch 216/300\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.3082 - binary_accuracy: 0.8499\n",
      "Epoch 217/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3114 - binary_accuracy: 0.8484\n",
      "Epoch 218/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.3078 - binary_accuracy: 0.8524\n",
      "Epoch 219/300\n",
      "32/32 [==============================] - 3s 104ms/step - loss: 0.3051 - binary_accuracy: 0.8536\n",
      "Epoch 220/300\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 0.3069 - binary_accuracy: 0.8504\n",
      "Epoch 221/300\n",
      "32/32 [==============================] - 3s 90ms/step - loss: 0.3043 - binary_accuracy: 0.8539\n",
      "Epoch 222/300\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.3046 - binary_accuracy: 0.8510\n",
      "Epoch 223/300\n",
      "32/32 [==============================] - 3s 90ms/step - loss: 0.3023 - binary_accuracy: 0.8521\n",
      "Epoch 224/300\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.3081 - binary_accuracy: 0.8499\n",
      "Epoch 225/300\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 0.3061 - binary_accuracy: 0.8514\n",
      "Epoch 226/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 3s 95ms/step - loss: 0.3052 - binary_accuracy: 0.8508\n",
      "Epoch 227/300\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.3057 - binary_accuracy: 0.8516\n",
      "Epoch 228/300\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.2977 - binary_accuracy: 0.8573\n",
      "Epoch 229/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.3015 - binary_accuracy: 0.8520\n",
      "Epoch 230/300\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.3014 - binary_accuracy: 0.8541\n",
      "Epoch 231/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.2991 - binary_accuracy: 0.8561\n",
      "Epoch 232/300\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.3009 - binary_accuracy: 0.8514\n",
      "Epoch 233/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.3012 - binary_accuracy: 0.8544\n",
      "Epoch 234/300\n",
      "32/32 [==============================] - 3s 84ms/step - loss: 0.2977 - binary_accuracy: 0.8561\n",
      "Epoch 235/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.2977 - binary_accuracy: 0.8544\n",
      "Epoch 236/300\n",
      "32/32 [==============================] - 3s 99ms/step - loss: 0.3002 - binary_accuracy: 0.8545\n",
      "Epoch 237/300\n",
      "32/32 [==============================] - 3s 84ms/step - loss: 0.3001 - binary_accuracy: 0.8527\n",
      "Epoch 238/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.2982 - binary_accuracy: 0.8551\n",
      "Epoch 239/300\n",
      "32/32 [==============================] - 3s 84ms/step - loss: 0.2973 - binary_accuracy: 0.8560\n",
      "Epoch 240/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.2971 - binary_accuracy: 0.8560\n",
      "Epoch 241/300\n",
      "32/32 [==============================] - 3s 94ms/step - loss: 0.2974 - binary_accuracy: 0.8571\n",
      "Epoch 242/300\n",
      "32/32 [==============================] - 3s 92ms/step - loss: 0.2971 - binary_accuracy: 0.8541\n",
      "Epoch 243/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.2950 - binary_accuracy: 0.8585\n",
      "Epoch 244/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.2983 - binary_accuracy: 0.8545\n",
      "Epoch 245/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.2953 - binary_accuracy: 0.8554\n",
      "Epoch 246/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.2951 - binary_accuracy: 0.8535\n",
      "Epoch 247/300\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.2979 - binary_accuracy: 0.8535\n",
      "Epoch 248/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.2932 - binary_accuracy: 0.8568\n",
      "Epoch 249/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.2963 - binary_accuracy: 0.8562\n",
      "Epoch 250/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.2995 - binary_accuracy: 0.8541\n",
      "Epoch 251/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.2916 - binary_accuracy: 0.8566\n",
      "Epoch 252/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.2869 - binary_accuracy: 0.8609\n",
      "Epoch 253/300\n",
      "32/32 [==============================] - 3s 98ms/step - loss: 0.2876 - binary_accuracy: 0.8621\n",
      "Epoch 254/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.2903 - binary_accuracy: 0.8592\n",
      "Epoch 255/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.2935 - binary_accuracy: 0.8573\n",
      "Epoch 256/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.2859 - binary_accuracy: 0.8632\n",
      "Epoch 257/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.2873 - binary_accuracy: 0.8585\n",
      "Epoch 258/300\n",
      "32/32 [==============================] - 3s 98ms/step - loss: 0.2917 - binary_accuracy: 0.8592\n",
      "Epoch 259/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.2935 - binary_accuracy: 0.8601\n",
      "Epoch 260/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.2856 - binary_accuracy: 0.8590\n",
      "Epoch 261/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.2895 - binary_accuracy: 0.8560\n",
      "Epoch 262/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.2900 - binary_accuracy: 0.8588\n",
      "Epoch 263/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.2856 - binary_accuracy: 0.8608\n",
      "Epoch 264/300\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.2899 - binary_accuracy: 0.8602\n",
      "Epoch 265/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.2902 - binary_accuracy: 0.8619\n",
      "Epoch 266/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.2864 - binary_accuracy: 0.8618\n",
      "Epoch 267/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.2880 - binary_accuracy: 0.8585\n",
      "Epoch 268/300\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.2890 - binary_accuracy: 0.8614\n",
      "Epoch 269/300\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.2825 - binary_accuracy: 0.8660\n",
      "Epoch 270/300\n",
      "32/32 [==============================] - 3s 95ms/step - loss: 0.2850 - binary_accuracy: 0.8596\n",
      "Epoch 271/300\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.2883 - binary_accuracy: 0.8567\n",
      "Epoch 272/300\n",
      "32/32 [==============================] - 3s 90ms/step - loss: 0.2926 - binary_accuracy: 0.8593\n",
      "Epoch 273/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.2843 - binary_accuracy: 0.8612\n",
      "Epoch 274/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.2838 - binary_accuracy: 0.8634\n",
      "Epoch 275/300\n",
      "32/32 [==============================] - 3s 104ms/step - loss: 0.2853 - binary_accuracy: 0.8606\n",
      "Epoch 276/300\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.2795 - binary_accuracy: 0.8622\n",
      "Epoch 277/300\n",
      "32/32 [==============================] - 3s 103ms/step - loss: 0.2844 - binary_accuracy: 0.8638\n",
      "Epoch 278/300\n",
      "32/32 [==============================] - 3s 92ms/step - loss: 0.2806 - binary_accuracy: 0.8629\n",
      "Epoch 279/300\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.2834 - binary_accuracy: 0.8616\n",
      "Epoch 280/300\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 0.2838 - binary_accuracy: 0.8608\n",
      "Epoch 281/300\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.2856 - binary_accuracy: 0.8601\n",
      "Epoch 282/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.2900 - binary_accuracy: 0.8598\n",
      "Epoch 283/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.2836 - binary_accuracy: 0.8644\n",
      "Epoch 284/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.2808 - binary_accuracy: 0.8627\n",
      "Epoch 285/300\n",
      "32/32 [==============================] - 3s 92ms/step - loss: 0.2816 - binary_accuracy: 0.8650\n",
      "Epoch 286/300\n",
      "32/32 [==============================] - 3s 100ms/step - loss: 0.2798 - binary_accuracy: 0.8628\n",
      "Epoch 287/300\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.2826 - binary_accuracy: 0.8639\n",
      "Epoch 288/300\n",
      "32/32 [==============================] - 3s 90ms/step - loss: 0.2764 - binary_accuracy: 0.8627\n",
      "Epoch 289/300\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.2784 - binary_accuracy: 0.8647\n",
      "Epoch 290/300\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.2752 - binary_accuracy: 0.8674\n",
      "Epoch 291/300\n",
      "32/32 [==============================] - 3s 108ms/step - loss: 0.2814 - binary_accuracy: 0.8627\n",
      "Epoch 292/300\n",
      "32/32 [==============================] - 3s 90ms/step - loss: 0.2792 - binary_accuracy: 0.8626\n",
      "Epoch 293/300\n",
      "32/32 [==============================] - 3s 90ms/step - loss: 0.2766 - binary_accuracy: 0.8670\n",
      "Epoch 294/300\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.2781 - binary_accuracy: 0.8659\n",
      "Epoch 295/300\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.2793 - binary_accuracy: 0.8637\n",
      "Epoch 296/300\n",
      "32/32 [==============================] - 3s 101ms/step - loss: 0.2777 - binary_accuracy: 0.8638\n",
      "Epoch 297/300\n",
      "32/32 [==============================] - 3s 95ms/step - loss: 0.2760 - binary_accuracy: 0.8665\n",
      "Epoch 298/300\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.2756 - binary_accuracy: 0.8648\n",
      "Epoch 299/300\n",
      "32/32 [==============================] - 3s 90ms/step - loss: 0.2724 - binary_accuracy: 0.8668\n",
      "Epoch 300/300\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.2738 - binary_accuracy: 0.8673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff26d63b8e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,\n",
    "          y=y_train,\n",
    "          epochs=300,\n",
    "          batch_size=256,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7952630b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "losses[['loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa191010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 2s 7ms/step\n",
      "134/134 [==============================] - 1s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.87      0.88      4011\n",
      "        True       0.87      0.90      0.89      4043\n",
      "\n",
      "    accuracy                           0.88      8054\n",
      "   macro avg       0.88      0.88      0.88      8054\n",
      "weighted avg       0.88      0.88      0.88      8054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix  \n",
    "predictions = (model.predict(X_train) > 0.5).astype(\"bool\")\n",
    "y_test_tf = (model.predict(X_test) > 0.5).astype('bool')\n",
    "print(classification_report(y_train,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdb9c804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3471,  540],\n",
       "       [ 399, 3644]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03206b53",
   "metadata": {},
   "source": [
    "## Exporting Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a382b190",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "224f435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = pd.read_csv('sample_submission.csv')\n",
    "y_test_lg.astype(bool)\n",
    "subs['Transported'] = y_test_lg\n",
    "\n",
    "subs.to_csv('Transported_lg.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2437fc5f",
   "metadata": {},
   "source": [
    "### Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0522a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = pd.read_csv('sample_submission.csv')\n",
    "y_test_rfc.astype(bool)\n",
    "subs['Transported'] = y_test_rfc\n",
    "\n",
    "subs.to_csv('Transported_rfc.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c9bb16",
   "metadata": {},
   "source": [
    "### K-Nearest Neigbhour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a45f3db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = pd.read_csv('sample_submission.csv')\n",
    "y_test_knn.astype(bool)\n",
    "subs['Transported'] = y_test_knn\n",
    "\n",
    "subs.to_csv('Transported_knn.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9492f685",
   "metadata": {},
   "source": [
    "### Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e7d9858",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = pd.read_csv('sample_submission.csv')\n",
    "y_test_tf.astype(bool)\n",
    "subs['Transported'] = y_test_tf\n",
    "\n",
    "subs.to_csv('Transported_tf.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
